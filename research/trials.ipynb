{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2973a1",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15b061d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51af208d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\SATHVIK\\\\Desktop\\\\Medical-Chatbot\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11f005a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfeadb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\SATHVIK\\\\Desktop\\\\Medical-Chatbot'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbbfae78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SATHVIK\\anaconda3\\envs\\medibot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c789cf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637\n"
     ]
    }
   ],
   "source": [
    "def pdf_loader(data):\n",
    "    loader = DirectoryLoader(\n",
    "        data,\n",
    "        glob='*.pdf',\n",
    "        loader_cls=PyPDFLoader\n",
    "    )\n",
    "\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "extracted_data = pdf_loader('data')\n",
    "print(len(extracted_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4a161c",
   "metadata": {},
   "source": [
    "## Data Filteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb19c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "def filter_to_minimal_docs(docs: List[Document]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Given a list of Document objects, return a new list of Document objects\n",
    "    containing only 'source' in metadata and the original page_content.\n",
    "    \"\"\"\n",
    "    minimal_docs: List[Document] = []\n",
    "    for doc in docs:\n",
    "        src = doc.metadata.get(\"source\")\n",
    "        minimal_docs.append(\n",
    "            Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={\"source\": src}\n",
    "            )\n",
    "        )\n",
    "    return minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1baafcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_docs = filter_to_minimal_docs(extracted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c57d77",
   "metadata": {},
   "source": [
    "## Data Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57f97888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(minimal_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20,\n",
    "    )\n",
    "    texts_chunk = text_splitter.split_documents(minimal_docs)\n",
    "    return texts_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bd09b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 5859\n"
     ]
    }
   ],
   "source": [
    "texts_chunk = text_split(minimal_docs)\n",
    "print(f\"Number of chunks: {len(texts_chunk)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d2271a",
   "metadata": {},
   "source": [
    "## Loading Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dd6113a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SATHVIK\\AppData\\Local\\Temp\\ipykernel_18728\\30168171.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_embeddings():\n",
    "    \"\"\"\n",
    "    Download and return the HuggingFace embeddings model.\n",
    "    \"\"\"\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_name\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "embedding = download_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0838410d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b571c20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = embedding.embed_query(\"Hello world\")\n",
    "len(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce553a45",
   "metadata": {},
   "source": [
    "## Creating PineCone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c04d285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77abed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "##read env\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "##set env\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ['GEMINI_API_KEY'] = GEMINI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bca4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone \n",
    "pinecone_api_key = PINECONE_API_KEY\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ee8e55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.pinecone.Pinecone at 0x1f65525d330>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be1998b",
   "metadata": {},
   "source": [
    "## Creating and Adding data into PineCone Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a28a12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec \n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name = index_name,\n",
    "        dimension=384,  # Dimension of the embeddings\n",
    "        metric= \"cosine\",  # Cosine similarity\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d8def",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=texts_chunk,\n",
    "    embedding=embedding,\n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "737e366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Existing index \n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embedding\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aab167b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['09a89d7f-db6c-4bd9-8f67-2d2301a8e1f0']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dswith = Document(\n",
    "    page_content=\"dswithbappy is a youtube channel that provides tutorials on various topics.\",\n",
    "    metadata={\"source\": \"Youtube\"}\n",
    ")\n",
    "docsearch.add_documents(documents=[dswith])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "837007e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3ca3425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='263b909f-dc01-4538-89e7-6a0b36e8a380', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 226\\nAcne\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26'),\n",
       " Document(id='b3835902-757b-4865-8a0d-7620b6d82f91', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 2 25\\nAcne\\nAcne vulgaris affecting a womanâ€™s face. Acne is the general\\nname given to a skin disorder in which the sebaceous\\nglands become inflamed. (Photograph by Biophoto Associ-\\nates, Photo Researchers, Inc. Reproduced by permission.)\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 25'),\n",
       " Document(id='758bc168-c95c-4f3b-8f40-e2cc81c08817', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='Acidosis see Respiratory acidosis; Renal\\ntubular acidosis; Metabolic acidosis\\nAcne\\nDefinition\\nAcne is a common skin disease characterized by\\npimples on the face, chest, and back. It occurs when the\\npores of the skin become clogged with oil, dead skin\\ncells, and bacteria.\\nDescription\\nAcne vulgaris, the medical term for common acne, is\\nthe most common skin disease. It affects nearly 17 million\\npeople in the United States. While acne can arise at any')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is Acne?\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e9d915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SATHVIK\\anaconda3\\envs\\medibot\\lib\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.19) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "c:\\Users\\SATHVIK\\anaconda3\\envs\\medibot\\lib\\site-packages\\langchain_google_genai\\chat_models.py:47: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  from google.generativeai.caching import CachedContent  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# chatModel = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from google import genai\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\", # Note: Check your model string; 1.5 is the current stable version\n",
    "    google_api_key=GEMINI_API_KEY, \n",
    "    temperature=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53d9713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5f4395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an Medical assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6702007",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(model, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a60137a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acromegaly is a disorder caused by the abnormal release of a chemical from the pituitary gland, leading to increased growth in bone and soft tissue. Gigantism occurs when this growth abnormality happens before bone growth has stopped, resulting in unusual height. Acromegaly, on the other hand, is diagnosed when the abnormality manifests after bone growth has ceased.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = rag_chain.invoke({\"input\": \"what is Acromegaly and gigantism?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
